{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for Research Homework: Week 3, Case Study 2\n",
    "\n",
    "In this case study, we will find and plot the distribution of word frequencies for each translation of Hamlet.  Perhaps the distribution of word frequencies of Hamlet depends on the translation --- let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT THIS CODE!\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def count_words_fast(text):\n",
    "    text = text.lower()\n",
    "    skips = [\".\", \",\", \";\", \":\", \"'\", '\"', \"\\n\", \"!\", \"?\", \"(\", \")\"]\n",
    "    for ch in skips:\n",
    "        text = text.replace(ch, \"\")\n",
    "    word_counts = Counter(text.split(\" \"))\n",
    "    return word_counts\n",
    "\n",
    "def read_book(title_path):\n",
    "    text   = pd.read_csv(title_path, sep = \"\\n\", engine='python', encoding=\"utf8\")\n",
    "    text = text.to_string(index = False)\n",
    "    return text\n",
    "\n",
    "def word_stats(word_counts):\n",
    "    num_unique = len(word_counts)\n",
    "    counts = word_counts.values()\n",
    "    return (num_unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 \n",
    "\n",
    "In this case study, we will find and visualize summary statistics of the text of different translations of Hamlet. For this case study, functions `count_words_fast`, `read_book`, and `word_stats` are already defined as in the Case 2 Videos (Videos 3.2.x).\n",
    "\n",
    "#### Instructions \n",
    "- Read in the data as a pandas dataframe using `pd.read_csv`. The data can be found at https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@hamlets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     language                                               text\n",
      "0     English  The Tragedie of Hamlet\\n                      ...\n",
      "1      German  Hamlet, Prinz von DÃ¤nnemark.\\n                ...\n",
      "2  Portuguese  HAMLET\\n                             DRAMA EM ...\n",
      "\n",
      "#: 3\n"
     ]
    }
   ],
   "source": [
    "hamlets = pd.read_csv(\"/Users/adityavenkat/Desktop/BITS/Data Science/EdX/Python Research/hamlets.csv\", usecols= ['language','text'])  ## Complete this line of code! ##\n",
    "print(hamlets.head())\n",
    "\n",
    "print(\"\\n#: \" + str(len(hamlets.language)))\n",
    "#print(hamlets[,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 \n",
    "\n",
    "In this exercise, we will summarize the text for a single translation of Hamlet in a `pandas` dataframe. \n",
    "\n",
    "#### Instructions\n",
    "- Find the dictionary of word frequency in `text` by calling `count_words_fast()`. Store this as `counted_text`.\n",
    "- Create a `pandas` dataframe named `data`.\n",
    "- Using `counted_text`, define two columns in data:\n",
    "    - `word`, consisting of each unique word in text.\n",
    "    - `count`, consisting of the number of times each word in `word` is included in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word  count\n",
      "0       the    935\n",
      "1  tragedie      3\n",
      "2        of    576\n",
      "3    hamlet     97\n",
      "4            45513\n",
      "97\n",
      "     word  count\n",
      "3  hamlet     97\n"
     ]
    }
   ],
   "source": [
    "[language, text] = hamlets.iloc[0]\n",
    "\n",
    "# Enter your code here.\n",
    "counted_text = count_words_fast(text)\n",
    "\n",
    "data = pd.DataFrame({'word': list(counted_text.keys()), 'count': list(counted_text.values())})\n",
    "print(data.head())\n",
    "\n",
    "print(data[data.word=='hamlet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "In this exercise, we will continue to define summary statistics for a single translation of Hamlet. \n",
    "\n",
    "#### Instructions\n",
    "- Add a column to data named `length`, defined as the length of each word.\n",
    "- Add another column named `frequency`, which is defined as follows for each word in `data`:\n",
    "    - If `count > 10`, `frequency` is \"frequent\".\n",
    "    - If `1 < count <= 10`, `frequency` is \"infrequent\".\n",
    "    - If `count == 1`, `frequency` is \"unique\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word  count  length   frequency\n",
      "0       the    935       3    frequent\n",
      "1  tragedie      3       8  infrequent\n",
      "2        of    576       2    frequent\n",
      "3    hamlet     97       6    frequent\n",
      "4            45513       0    frequent\n",
      "(5113, 4)\n",
      "(3348, 4)\n"
     ]
    }
   ],
   "source": [
    "# write your code here!\n",
    "data[\"length\"]=data[\"word\"].str.len()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data[\"frequency\"] = np.where(data[\"count\"]>10,\"frequent\",np.where(data[\"count\"]>1,\"infrequent\",\"unique\"))\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data[data.frequency==\"unique\"].shape)\n",
    "#print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise, we will summarize the statistics in data into a smaller pandas dataframe. \n",
    "\n",
    "#### Instructions \n",
    "- Create a `pandas` dataframe named `sub_data` including the following columns:\n",
    "    - `language`, which is the language of the text.\n",
    "    - `frequency`, which is a list containing the strings \"frequent\", \"infrequent\", and \"unique\".\n",
    "    - `mean_word_length`, which is the mean word length of each value in frequency.\n",
    "    - `num_words`, which is the total number of words in each frequency category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    frequency    length\n",
      "0    frequent  4.371517\n",
      "1  infrequent  5.825243\n",
      "2      unique  7.005675\n",
      "frequency\n",
      "frequent       323\n",
      "infrequent    1442\n",
      "unique        3348\n",
      "Name: word, dtype: int64\n",
      "    frequency    length   frequency  word\n",
      "0    frequent  4.371517    frequent   323\n",
      "1  infrequent  5.825243  infrequent  1442\n",
      "2      unique  7.005675      unique  3348\n"
     ]
    }
   ],
   "source": [
    "# write your code here!\n",
    "\n",
    "\n",
    "#ONLY PARTIALLY COMPLETE, REFER TO THE FUNCTION IN THE NEXT QUESTION TO GET AN ANSWER!!\n",
    "\n",
    "sub_data_1 = data.groupby([\"frequency\"], as_index = False).length.mean()\n",
    "\n",
    "print(sub_data_1)\n",
    "\n",
    "sub_data_2 = data.groupby([\"frequency\"]).word.count()\n",
    "\n",
    "print(sub_data_2)\n",
    "\n",
    "sub_data_3 = pd.concat([data.groupby([\"frequency\"], as_index=False).length.mean(),data.groupby([\"frequency\"], as_index = False).word.count()], axis = 1)\n",
    "\n",
    "print(sub_data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "In this exercise, we will join all the data summaries for text Hamlet translation.\n",
    "\n",
    "#### Instructions \n",
    "- The previous code for summarizing a particular translation of Hamlet is consolidated into a single function called `summarize_text`. Create a pandas dataframe` grouped_data` consisting of the results of `summarize_text` for each translation of Hamlet in `hamlets`.\n",
    "    - Use a `for` loop across the row indices of `hamlets` to assign each translation to a new row.\n",
    "    - Obtain the `ith` row of `hamlets` to variables using the `.iloc` method, and assign the output to variables `language` and `text`.\n",
    "    - Call `summarize_text` using `language` and `text`, and assign the output to `sub_data`.\n",
    "    - Use the pandas `.append()` function to append to pandas dataframes row-wise to `grouped_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              language   frequency  mean_word_length  num_words\n",
      "frequency                                                      \n",
      "frequent       English    frequent          4.371517        323\n",
      "infrequent     English  infrequent          5.825243       1442\n",
      "unique         English      unique          7.005675       3348\n",
      "frequent        German    frequent          4.528053        303\n",
      "infrequent      German  infrequent          6.481830       1596\n",
      "unique          German      unique          9.006987       5582\n",
      "frequent    Portuguese    frequent          4.417625        261\n",
      "infrequent  Portuguese  infrequent          6.497870       1643\n",
      "unique      Portuguese      unique          8.669778       5357\n"
     ]
    }
   ],
   "source": [
    "def summarize_text(language, text):\n",
    "    counted_text = count_words_fast(text)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        \"word\": list(counted_text.keys()),\n",
    "        \"count\": list(counted_text.values())\n",
    "    })\n",
    "    \n",
    "    data.loc[data[\"count\"] > 10,  \"frequency\"] = \"frequent\"\n",
    "    data.loc[data[\"count\"] <= 10, \"frequency\"] = \"infrequent\"\n",
    "    data.loc[data[\"count\"] == 1,  \"frequency\"] = \"unique\"\n",
    "    \n",
    "    data[\"length\"] = data[\"word\"].apply(len)\n",
    "    \n",
    "    sub_data = pd.DataFrame({\n",
    "        \"language\": language,\n",
    "        \"frequency\": [\"frequent\",\"infrequent\",\"unique\"],\n",
    "        \"mean_word_length\": data.groupby(by = \"frequency\")[\"length\"].mean(),\n",
    "        \"num_words\": data.groupby(by = \"frequency\").size()\n",
    "    })\n",
    "    \n",
    "    return(sub_data)\n",
    "    \n",
    "# write your code here!\n",
    "for i in range(len(hamlets)):\n",
    "    if i == 0:\n",
    "        [language, text] = hamlets.iloc[i]\n",
    "        grouped_data = summarize_text(language, text)\n",
    "    else:\n",
    "        [language, text] = hamlets.iloc[i]        \n",
    "        grouped_data = grouped_data.append(summarize_text(language, text))\n",
    "        \n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "In this exercise, we will plot our results and look for differences across each translation.\n",
    "\n",
    "#### Instructions \n",
    "- Plot the word statistics of each translations on a single plot. Note that we have already done most of the work for you.\n",
    "- Consider: do the word statistics differ by translation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language               English\n",
      "frequency           infrequent\n",
      "mean_word_length       5.82524\n",
      "num_words                 1442\n",
      "Name: infrequent, dtype: object\n",
      "infrequent English\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"Portuguese\": \"green\", \"English\": \"blue\", \"German\": \"red\"}\n",
    "markers = {\"frequent\": \"o\",\"infrequent\": \"s\", \"unique\": \"^\"}\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(grouped_data.shape[0]):\n",
    "    row = grouped_data.iloc[i]\n",
    "    plt.plot(row.mean_word_length, row.num_words,\n",
    "        marker=markers[row.frequency],\n",
    "        color = colors[row.language],\n",
    "        markersize = 10\n",
    "    )\n",
    "\n",
    "color_legend = []\n",
    "marker_legend = []\n",
    "for color in colors:\n",
    "    color_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=colors[color],\n",
    "        marker=\"o\",\n",
    "        label = color, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "for marker in markers:\n",
    "    marker_legend.append(\n",
    "        plt.plot([], [],\n",
    "        color=\"k\",\n",
    "        marker=markers[marker],\n",
    "        label = marker, markersize = 10, linestyle=\"None\")\n",
    "    )\n",
    "plt.legend(numpoints=1, loc = \"upper left\")\n",
    "\n",
    "plt.xlabel(\"Mean Word Length\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "# write your code to display the plot here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
